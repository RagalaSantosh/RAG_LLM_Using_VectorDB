**Overview**

This project implements a **Retrieval-Augmented Generation (RAG)** system using **OpenAI's Language Model (LLM)** and **Pinecone as the vector database** for storing text embeddings. RAG systems combine the benefits of traditional information retrieval systems with modern language models for more accurate and contextually relevant responses.

**Features**
1. **OpenAI Language Model:** Utilizes OpenAI's Language Model (LLM) for generating responses and retrieving relevant information.
2. **Pinecone Integration:** Integrates with Pinecone as the vector database for storing text embeddings, enabling efficient similarity search.
3. **Retrieval-Augmented Generation:** Implements a RAG system architecture to provide contextually relevant responses by combining retrieval and generation techniques.
4. **Scalable and Fast:** Pinecone's scalable infrastructure ensures fast and efficient retrieval of embeddings for real-time applications.

**Setup**

**Install Dependencies:** Make sure to install the required Python dependencies. You can install them using pip:
pip install -r requirements.txt

**Pinecone Setup:** Obtain your Pinecone API key and set it as an environment variable
**OpenAI Setup:** Obtain your OpenAI API key and set it as an environment variable:

**Execution:**
Please run the **code.py**
